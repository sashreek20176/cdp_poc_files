<?xml version="1.0" encoding="UTF-8"?>

<!--Autogenerated by Cloudera Manager-->
<configuration>
  <property>
    <name>dfs.hosts</name>
    <value>{{CMF_CONF_DIR}}/dfs_all_hosts.txt</value>
  </property>
  <property>
    <name>dfs.namenode.hosts.provider.classname</name>
    <value>org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:///dfs/nn</value>
  </property>
  <property>
    <name>dfs.namenode.servicerpc-address</name>
    <value>ip-172-31-32-101.us-east-2.compute.internal:8022</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address</name>
    <value>ip-172-31-32-101.us-east-2.compute.internal:8020</value>
  </property>
  <property>
    <name>dfs.https.address</name>
    <value>ip-172-31-32-101.us-east-2.compute.internal:9871</value>
  </property>
  <property>
    <name>dfs.https.port</name>
    <value>9871</value>
  </property>
  <property>
    <name>dfs.namenode.http-address</name>
    <value>ip-172-31-32-101.us-east-2.compute.internal:9870</value>
  </property>
  <property>
    <name>dfs.namenode.secondary.http-address</name>
    <value>ip-172-31-32-101.us-east-2.compute.internal:9868</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>supergroup</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>3</value>
  </property>
  <property>
    <name>dfs.namenode.replication.min</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.replication.max</name>
    <value>512</value>
  </property>
  <property>
    <name>dfs.namenode.maintenance.replication.min</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>134217728</value>
  </property>
  <property>
    <name>dfs.namenode.accesstime.precision</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.startup.delay.block.deletion.sec</name>
    <value>3600</value>
  </property>
  <property>
    <name>dfs.image.transfer.timeout</name>
    <value>60000</value>
  </property>
  <property>
    <name>dfs.image.transfer.bandwidthPerSec</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>30</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>30</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir.restore</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.thrift.threads.max</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.thrift.threads.min</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.thrift.timeout</name>
    <value>60</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.fs-limits.max-component-length</name>
    <value>255</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value>0.999</value>
  </property>
  <property>
    <name>dfs.namenode.invalidate.work.pct.per.iteration</name>
    <value>0.32</value>
  </property>
  <property>
    <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.namenode.replication.max-streams</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.namenode.replication.max-streams-hard-limit</name>
    <value>40</value>
  </property>
  <property>
    <name>dfs.namenode.audit.log.async</name>
    <value>true</value>
  </property>
  <property>
    <name>hadoop.caller.context.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.avoid.read.stale.datanode</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.snapshot.capture.openfiles</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.avoid.write.stale.datanode</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.stale.datanode.interval</name>
    <value>30000</value>
  </property>
  <property>
    <name>dfs.namenode.write.stale.datanode.ratio</name>
    <value>0.5</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.min.datanodes</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value>30000</value>
  </property>
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>022</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer.algorithm</name>
    <value>rc4</value>
  </property>
  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.access.time.precision</name>
    <value>3600000</value>
  </property>
  <property>
    <name>dfs.qjournal.write-txns.timeout.ms</name>
    <value>20000</value>
  </property>
  <property>
    <name>dfs.qjournal.start-segment.timeout.ms</name>
    <value>20000</value>
  </property>
  <property>
    <name>dfs.qjournal.prepare-recovery.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.accept-recovery.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.finalize-segment.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.select-input-streams.timeout.ms</name>
    <value>20000</value>
  </property>
  <property>
    <name>dfs.qjournal.get-journal-state.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.qjournal.new-epoch.timeout.ms</name>
    <value>120000</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.decommission.blocks.per.interval</name>
    <value>500000</value>
  </property>
  <property>
    <name>dfs.namenode.decommission.max.concurrent.tracked.nodes</name>
    <value>100</value>
  </property>
  <property>
    <name>dfs.namenode.ec.system.default.policy</name>
    <value>RS-6-3-1024k</value>
  </property>
</configuration>